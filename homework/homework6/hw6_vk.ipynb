{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from credentials import token\n",
    "from requests.exceptions import HTTPError, Timeout\n",
    "from datetime import date, datetime\n",
    "from pymystem3 import Mystem\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives a datetime object, converts it into age\n",
    "def get_age(birthday):\n",
    "    today = date.today()\n",
    "    age_s = today.year - birthday.year\n",
    "    if today.month < birthday.month:\n",
    "        age_s -= 1\n",
    "    elif today.month == birthday.month and today.day < birthday.day:\n",
    "        age_s -= 1\n",
    "    return age_s\n",
    "\n",
    "\n",
    "# Thoroughly cleans the string\n",
    "def clean(string):\n",
    "    string = string.replace(',', '!').replace('!', '?')\n",
    "    string = string.replace('?', '.').replace('.', '-')\n",
    "    string = string.replace('-', ':').replace(':', ';')\n",
    "    string = string.replace(';', ')').replace(')', '(')\n",
    "    string = string.replace('(', '').replace('—', '').strip()\n",
    "    return string\n",
    "\n",
    "\n",
    "# Prepares data for csv\n",
    "def reformat_csv(status, post_id, poster_id, first_name, last_name,\n",
    "                 sex, city, bdate, age, education, text):\n",
    "    clean_text = clean(text)\n",
    "    length = len(clean_text)\n",
    "    string = '%s,%s,%s,%s,%s,%s,%s,%s,%s,\"%s\",%s,\"%s\"' % (\n",
    "        status, post_id, poster_id, first_name, last_name,\n",
    "        sex, city, bdate, age, education, length, text)\n",
    "    return string\n",
    "\n",
    "\n",
    "# Appends lines to a csv file\n",
    "def make_csv(line):\n",
    "    string = 'status,post_id,owner_id,name,surname,sex,city,' \\\n",
    "             'bdate,age,education,length,text,comments_id\\n'\n",
    "    if not os.path.exists('stats.csv'):\n",
    "        with open('stats.csv', 'w', encoding='utf-8') as f:\n",
    "            f.write(string)\n",
    "    with open('stats.csv', 'a', encoding='utf-8') as f:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all the necessary user info\n",
    "def get_poster_info(poster_id, token):\n",
    "    if poster_id < 0:\n",
    "        (first_name, last_name, sex, city, bdate,\n",
    "         age, education) = None, None, None, None, None, None, None\n",
    "        return first_name, last_name, sex, city, bdate, age, education\n",
    "    # new parameters for users.get method\n",
    "    params = {'access_token': token, 'v': '5.95', 'user_id': poster_id,\n",
    "              'fields': 'city,sex,first_name,last_name,bdate,education'}\n",
    "    try:\n",
    "        req = requests.get('https://api.vk.com/method/users.get',\n",
    "                           params=params)\n",
    "        data = req.text\n",
    "        req.raise_for_status()\n",
    "    except HTTPError or Timeout:\n",
    "        print('Could not get User Info')\n",
    "        return None\n",
    "    else:\n",
    "        data = json.loads(data)\n",
    "        try:\n",
    "            items = data['response'][0]\n",
    "        except KeyError:\n",
    "            return None\n",
    "        else:\n",
    "            first_name = items['first_name']  # poster/commenter name\n",
    "            last_name = items['last_name']  # poster/commenter surname\n",
    "            sex = items['sex']\n",
    "            # specifies user's sex\n",
    "            if sex == 1:\n",
    "                sex = 'female'\n",
    "            elif sex == 2:\n",
    "                sex = 'male'\n",
    "            else:\n",
    "                sex = 'unspecified'\n",
    "            # tries to get the name of the city\n",
    "            try:\n",
    "                city = items['city']['title']\n",
    "            except KeyError:\n",
    "                city = None\n",
    "            # gets user's age if possible\n",
    "            try:\n",
    "                bdate = items['bdate']\n",
    "            except KeyError:\n",
    "                bdate = None\n",
    "                age = None\n",
    "            else:\n",
    "                try:\n",
    "                    day, month, year = bdate.split('.')\n",
    "                except ValueError:\n",
    "                    age = None\n",
    "                else:\n",
    "                    time_string = day + '/' + month + '/' + year\n",
    "                    birthday = datetime.strptime(time_string, '%d/%m/%Y')\n",
    "                    age = get_age(birthday)\n",
    "            # tries to get one of the degrees if given\n",
    "            try:\n",
    "                education = items['university_name']\n",
    "            except KeyError:\n",
    "                education = None\n",
    "            else:\n",
    "                education = clean(education)\n",
    "    return first_name, last_name, sex, city, bdate, age, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets comments for post, returns info about a commenter\n",
    "def get_comment_info(post_id, community_id, token):\n",
    "    # while True, try to get the post's comments\n",
    "    comments = []\n",
    "    strings = []\n",
    "    offset = 0\n",
    "    while True:\n",
    "        if offset:\n",
    "            params = {'access_token': token, 'v': '5.95',\n",
    "                      'owner_id': community_id, 'post_id': post_id,\n",
    "                      'count': 100, 'offset': offset}\n",
    "        else:\n",
    "            params = {'access_token': token, 'v': '5.95',\n",
    "                      'owner_id': community_id, 'post_id': post_id,\n",
    "                      'count': 100}  # all parameters\n",
    "        try:\n",
    "            req = requests.get('https://api.vk.com/method/wall.getComments',\n",
    "                               params=params)\n",
    "            data = req.text\n",
    "            req.raise_for_status()  # as usual, we try to mine stuff\n",
    "        except HTTPError or Timeout:\n",
    "            print('Could not mine wall for data')\n",
    "        else:\n",
    "            status = 'comment'\n",
    "            data = json.loads(data)\n",
    "            items = data['response']['items']\n",
    "            if not items:  # if no comments, returns blank list\n",
    "                break\n",
    "            offset += 100\n",
    "            for item in items:\n",
    "                try:\n",
    "                    text = item['text']\n",
    "                except KeyError:\n",
    "                    text = None\n",
    "                else:\n",
    "                    text = text.replace('\\n', ' ')\n",
    "                comment_id = item['id']\n",
    "                try:\n",
    "                    poster_id = item['from_id']\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                else:\n",
    "                    # gets info on the commenter\n",
    "                    (first_name, last_name, sex, city, bdate,\n",
    "                     age, education) = get_poster_info(poster_id, token)\n",
    "                    comments.append(comment_id)  # gets list of comments\n",
    "                    # makes a string ready for csv input\n",
    "                    string = reformat_csv(status, post_id, poster_id,\n",
    "                                          first_name, last_name, sex,\n",
    "                                          city, bdate, age, education, text)\n",
    "                    string += ',' + str(comment_id) + '\\n'\n",
    "                    strings.append(string)\n",
    "    return comments, strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all the necessary info to make csv\n",
    "def get_poster():\n",
    "    offset = 0\n",
    "    # while True, tries to get data\n",
    "    while True:\n",
    "        print('Posts mined', ':', offset)\n",
    "        token = input('Ваш токен: ')\n",
    "        # giving the necessary parameters\n",
    "        params = {'access_token': token, 'domain': 'proekt_ne_gotov',\n",
    "                  'v': '5.95', 'offset': offset, 'count': '100'}\n",
    "        try:\n",
    "            req = requests.get('https://api.vk.com/method/wall.get',\n",
    "                               params=params)\n",
    "            data = req.text\n",
    "            req.raise_for_status()\n",
    "            # if download successful, proceeds to work with data\n",
    "        except HTTPError or Timeout:\n",
    "            print('Could not mine wall for data')\n",
    "        else:\n",
    "            data = json.loads(data)\n",
    "            items = data['response']['items']\n",
    "            if not items:\n",
    "                break  # kills the process when offset reaches a limit\n",
    "            for item in items:\n",
    "                post_id = item['id']  # gets the id of the post\n",
    "                community_id = item['owner_id']\n",
    "                # i don't know why my code does this every cycle, must rewrite\n",
    "                text = item['text']  # gets the messages text\n",
    "                try:\n",
    "                    poster_id = item['signer_id']  # some posts are not signed\n",
    "                except KeyError:\n",
    "                    poster_id = community_id\n",
    "                if poster_id != community_id:\n",
    "                    (first_name, last_name, sex, city, bdate,\n",
    "                     age, education) = get_poster_info(poster_id, token)\n",
    "                    status = 'post'\n",
    "                    comments, strings =\\\n",
    "                        get_comment_info(post_id, community_id, token)\n",
    "                    text = text.replace('\\n', ' ')\n",
    "                    post = reformat_csv(status, post_id, poster_id,\n",
    "                                        first_name, last_name, sex, city,\n",
    "                                        bdate, age, education, text)\n",
    "                    post += ',' + str(comments) + '\\n'\n",
    "                    make_csv(post)\n",
    "                    for string in strings:\n",
    "                        make_csv(string)\n",
    "            offset += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making unlemmatized files\n",
    "def making_unlem():\n",
    "    with open('stats.csv', 'r', encoding='utf-8') as f:\n",
    "        text = f.readlines()\n",
    "    lis_t = []\n",
    "    for line in text:\n",
    "        sline = re.search('\"(.*)\"', line)\n",
    "        if sline:\n",
    "            lis = re.search(',\"(.*)\"', sline.group())\n",
    "            if lis:\n",
    "                lis = lis.group().replace(',\"', '\"').strip('\"') + '\\n'\n",
    "                if lis:\n",
    "                    lis_t.append(lis)\n",
    "    with open('non_lemm_text.txt', 'w', encoding='utf-8') as f:\n",
    "        f.writelines(lis_t)\n",
    "\n",
    "# Making lemmatized files\n",
    "def making_lem():\n",
    "    with open('non_lemm_text.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.readlines()\n",
    "    m = Mystem()\n",
    "    print('making lemmatized file')\n",
    "    lemlines = []\n",
    "    i = 0\n",
    "    for line in text:\n",
    "        if line == '\\n':\n",
    "            pass\n",
    "        else:\n",
    "            lemline = m.lemmatize(line)\n",
    "            i += 1\n",
    "            print('lemmatized line: ', i)\n",
    "            lemlines.append(lemline)\n",
    "    with open('lemm_text.txt', 'w', encoding='utf-8') as f:\n",
    "        for line in lemlines:\n",
    "            f.writelines(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all the necessary params for graphs\n",
    "def parameters():\n",
    "    with open('stats.csv', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    sex_s = []\n",
    "    education_s = []\n",
    "    com_leng = []\n",
    "    citie_s = []\n",
    "    age_s = []\n",
    "    compared_length_s = []\n",
    "    length = 0\n",
    "    checker = lines[1].split(',')[1]\n",
    "    for line in lines:\n",
    "        sline = line.split(',')\n",
    "        if line.startswith('post'):\n",
    "            sex = sline[5]\n",
    "            education = sline[9]\n",
    "            length = int(sline[10])\n",
    "            sex_s.append((length, sex))\n",
    "            education_s.append((length, education))\n",
    "        else:\n",
    "            # если у коммента и поста один айди\n",
    "            pcom_id = sline[1]\n",
    "            try:\n",
    "                age = int(sline[8])\n",
    "                length_com = int(sline[10])\n",
    "            except ValueError:\n",
    "                length_com = 0\n",
    "            else:\n",
    "                city = sline[6]\n",
    "                age_s.append((length_com, age))\n",
    "                citie_s.append((length_com, city))\n",
    "            if checker == pcom_id:\n",
    "                try:\n",
    "                    leng = int(length_com)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                else:\n",
    "                    com_leng.append(leng)\n",
    "            else:\n",
    "                try:\n",
    "                    aver = sum(com_leng) / len(com_leng)\n",
    "                except ZeroDivisionError:\n",
    "                    pass\n",
    "                else:\n",
    "                    compared_length_s.append((length, round(aver, 3)))\n",
    "                    checker = pcom_id\n",
    "    return sex_s, education_s, age_s, citie_s, compared_length_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing length of post with average length of its' comment\n",
    "def compared_graph(compared):\n",
    "    x = []\n",
    "    y = []\n",
    "    for key, value in sorted(compared, key=lambda z: z[0]):\n",
    "        x.append(key)\n",
    "        y.append(value)\n",
    "    plt.title('Сравнительная длина поста и его комментариев')\n",
    "    plt.xlabel('Длины поста')\n",
    "    plt.ylabel('Длины комментариев')\n",
    "    plt.plot(x, y, c='#ffa62b', marker='^')\n",
    "    plt.savefig('post_comment_lengths_compare.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing sex of poster with average length of their post\n",
    "def sex_graph(sex):\n",
    "    fem = []\n",
    "    mas = []\n",
    "    for length, sexs in sorted(sex, key=lambda z: z[0]):\n",
    "        if sexs == 'female':\n",
    "            fem.append(length)\n",
    "        else:\n",
    "            mas.append(length)\n",
    "    fem = sum(fem) / len(fem)\n",
    "    mas = sum(mas) / len(mas)\n",
    "    plt.title('Сравнение средней длины постов по полу')\n",
    "    plt.xlabel('Средняя длина поста')\n",
    "    plt.ylabel('Пол')\n",
    "    plt.bar(('male', 'female'), (mas, fem), align='center')\n",
    "    plt.savefig('sex_vs_post_length_bar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing education of poster with average length of post\n",
    "def education_graph(edu):\n",
    "    x = []\n",
    "    y = []\n",
    "    for key, value in sorted(edu, key=lambda z: z[0]):\n",
    "        if value != '\"None\"' and value != '\"\"':\n",
    "            x.append(key)\n",
    "            y.append(value)\n",
    "    plt.title('Сравнение длины поста с наличием образования')\n",
    "    plt.xlabel('Длина поста')\n",
    "    plt.ylabel('Образование')\n",
    "    plt.scatter(x, y, c='crimson', marker='D')\n",
    "    plt.savefig('education_vs_post_length.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing age of commenter with comment's length\n",
    "def age_graph(ag):\n",
    "    x = []\n",
    "    y = []\n",
    "    for key, value in sorted(ag, key=lambda z: z[0]):\n",
    "        x.append(key)\n",
    "        y.append(value)\n",
    "    plt.title('Сравнение длины комментариев с возрастом')\n",
    "    plt.xlabel('Длина комментариев')\n",
    "    plt.ylabel('Возраст')\n",
    "    plt.scatter(x, y, c='#fd798f', marker='X')\n",
    "    plt.savefig('age_vs_comment_length.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing city of commenter with comment's length\n",
    "def cities_graph(cit):\n",
    "    x = []\n",
    "    y = []\n",
    "    for key, value in sorted(cit, key=lambda z: z[0]):\n",
    "        if value != 'None' and key != 0:\n",
    "            x.append(key)\n",
    "            y.append(value)\n",
    "    plt.title('Сравнение длины комментариев с городом проживания')\n",
    "    plt.xlabel('Длина комментариев')\n",
    "    plt.ylabel('Город')\n",
    "    plt.scatter(x, y, c='#a87dc2', marker='*')\n",
    "    plt.savefig('city_vs_comment_length.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a graph for unlemmatized file\n",
    "def quantity_unlem():\n",
    "    x = []\n",
    "    y = []\n",
    "    with open('rus_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.readlines()\n",
    "    with open('non_lemm_text.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    clean_text = []\n",
    "    text = clean(text).split()\n",
    "    for word in text:\n",
    "        for stopword in stopwords:\n",
    "            if word == stopword.strip('\\n'):\n",
    "                word = ''\n",
    "        if word:\n",
    "            clean_text.append(word.lower())\n",
    "    d = dict(collections.Counter(clean_text).most_common(25))\n",
    "    for key, value in d.items():\n",
    "        x.append(key)\n",
    "        y.append(value)\n",
    "    plt.title('Частотные и нелемматизированные')\n",
    "    plt.xlabel('Слова')\n",
    "    plt.ylabel('Частотность')\n",
    "    plt.plot(x, y, c='#bffe28')\n",
    "    plt.savefig('quantitative_nonlemmatized.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a graph for a lemmatized file\n",
    "def quantity_lem():\n",
    "    x = []\n",
    "    y = []\n",
    "    with open('rus_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "        stopwords = f.readlines()\n",
    "    with open('lemm_text.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    clean_text = []\n",
    "    text = clean(text).split()\n",
    "    for word in text:\n",
    "        for stopword in stopwords:\n",
    "            if word == stopword.strip('\\n'):\n",
    "                word = ''\n",
    "        if word:\n",
    "            clean_text.append(word.lower())\n",
    "    d = dict(collections.Counter(clean_text).most_common(25))\n",
    "    for key, value in d.items():\n",
    "        x.append(key)\n",
    "        y.append(value)\n",
    "    plt.plot(x, y, c='#4da409')\n",
    "    plt.title('Частотные и лемматизированные')\n",
    "    plt.xlabel('Слова')\n",
    "    plt.ylabel('Частотность')\n",
    "    plt.savefig('quantitative_lemmatized.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    get_poster()\n",
    "    making_unlem()\n",
    "    making_lem()\n",
    "    sexes, educations, ages, cities, compared_lengths = parameters()\n",
    "    compared_graph(compared_lengths)\n",
    "    sex_graph(sexes)\n",
    "    education_graph(educations)\n",
    "    age_graph(ages)\n",
    "    cities_graph(cities)\n",
    "    quantity_unlem()\n",
    "    quantity_lem()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
